{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('utils/')\n",
    "from extract_classifiers import *\n",
    "from config import *\n",
    "from eval.captioner import *\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "coco_template = 'images/ipython_images/coco/COCO_val2014_%012d.jpg' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#build feature extractor\n",
    "\n",
    "#These lexical features are trained with MSCOCO images.  For images which include a held out class (e.g., \"zebra\") \n",
    "#only the held-out class is used as the label.  All other class labels are given a label of \"-1\" (or ignore label.)\n",
    "#For images which do not include a held out class, multiple labels\n",
    "#are mined from visual descriptions (e.g., \"A young girl with a blue sweater\" --> labels: \"young\", \"girl\", \"blue\",\n",
    "#\"sweater\") \n",
    "coco_model = 'prototxts/train_classifiers_deploy.prototxt'\n",
    "coco_model_weights = 'snapshots/attributes_JJ100_NN300_VB100_coco_471_eightCluster_0223_iter_80000.caffemodel'\n",
    "\n",
    "#These lexical features are trained with MSCOCO images and > 600 ImageNet classes specifically chosen such that they do\n",
    "#not overlap with categories seen in MSCOCO.  For all MSCOCO images, labels are mined from visual descriptions.  For \n",
    "#ImageNet images, categories mined from MSCOCO descriptions are given a \"-1\" (ignore label).  This is done because\n",
    "#in many ImageNet images classes like \"grass\" or \"yellow\" are present\n",
    "\n",
    "imagenet_model = 'prototxts/train_classifiers_deploy.prototxt'\n",
    "imagenet_model_weights = 'snapshots/attributes_JJ100_NN300_VB100_coco_471_eightCluster_0223_iter_80000.caffemodel'\n",
    "\n",
    "coco_extractor = VisualFeatureExtractor(coco_model, coco_model_weights, device=0, feature_extract='probs')\n",
    "coco_extractor.build_image_processor()\n",
    "\n",
    "imagenet_model = 'prototxts/train_classifiers_deploy.imagenet.prototxt'\n",
    "imagenet_model_weights = 'snapshots/vgg_multilabel_FT_iter_100000.caffemodel'\n",
    "\n",
    "imagenet_extractor = VisualFeatureExtractor(imagenet_model, imagenet_model_weights, device=0, feature_extract='probs')\n",
    "imagenet_extractor.build_image_processor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Extract features for coco and Imagenet images.\n",
    "\n",
    "def make_feature_dict(features, ims):\n",
    "    feature_dict = {}\n",
    "    for i, im in enumerate(ims):\n",
    "        feature_dict[im] = features[i,:]\n",
    "    return feature_dict\n",
    "        \n",
    "coco_images = [coco_template %im_id for im_id in [380868, 356368, 279846, 531563]]\n",
    "feature_dict_coco = make_feature_dict(coco_extractor.extract_batch_features(coco_images), coco_images)\n",
    "\n",
    "imagenet_images = ['images/ipython_images/' + im_id for im_id in ['otter/n02444819_13167.JPEG', \n",
    "                                                              'otter/n02444819_10502.JPEG',\n",
    "                                                              'alpaca/n02698473_518.JPEG',\n",
    "                                                              'candelabra/n02947818_15145.JPEG',\n",
    "                                                              'baobab/n12189987_4309.JPEG']]\n",
    "feature_dict_imagenet = make_feature_dict(imagenet_extractor.extract_batch_features(imagenet_images), imagenet_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captioning image: 0/4\n",
      "4/4 done after word 12\n",
      "Captioning image: 0/4\n",
      "4/4 done after word 12"
     ]
    }
   ],
   "source": [
    "#Build dcc captioner for coco and Imagenet\n",
    "def build_captioner(proto, weights, vocab):\n",
    "    language_model = models_folder + proto\n",
    "    model_weights = weights_folder + weights\n",
    "    vocab = vocab_root + vocab\n",
    "\n",
    "\n",
    "    captioner = Captioner(language_model, model_weights,\n",
    "                            sentence_generation_cont_in='cont_sentence',\n",
    "                            sentence_generation_sent_in='input_sentence',\n",
    "                            sentence_generation_feature_in=['image_features'],\n",
    "                            sentence_generation_out='predict',\n",
    "                            vocab_file=vocab,\n",
    "                            prev_word_restriction=True)\n",
    "    return captioner\n",
    "\n",
    "#coco models\n",
    "\n",
    "language_prototxt = 'dcc_vgg.wtd.prototxt'\n",
    "vocab = 'vocabulary.txt'\n",
    "coco_no_transfer_weights = 'dcc_coco_rm1_vgg.471.solver.prototxt_iter_110000.caffemodel'\n",
    "coco_transfer_weights = 'dcc_coco_rm1_vgg.471.solver.prototxt_iter_110000.transfer_words_coco1.txt_closeness_embedding.caffemodel'\n",
    "\n",
    "coco_no_transfer_captioner = build_captioner(language_prototxt, coco_no_transfer_weights, vocab)\n",
    "gen_captions_no_transfer = coco_no_transfer_captioner.caption_images(feature_dict_coco, \n",
    "                                                                     feature_dict_coco.keys(), batch_size=1000)\n",
    "\n",
    "coco_transfer_captioner = build_captioner(language_prototxt, coco_transfer_weights, vocab)\n",
    "gen_captions_transfer = coco_transfer_captioner.caption_images(feature_dict_coco, \n",
    "                                                      feature_dict_coco.keys(), batch_size=1000)\n",
    "\n",
    "#ImageNet models\n",
    "\n",
    "language_prototxt = 'dcc_vgg.80k.wtd.imagenet.prototxt'\n",
    "vocab = 'yt_coco_surface_80k_vocab.txt'\n",
    "imagenet_no_transfer_weights = 'vgg_feats.vgg_multilabel_FT_iter_100000_imagenetSentences_iter_110000.caffemodel'\n",
    "imagenet_transfer_weights = 'vgg_feats.vgg_multilabel_FT_iter_100000_imagenetSentences_iter_110000.transfer_words_imagenet.txt_closeness_embedding.caffemodel'\n",
    "\n",
    "imagenet_no_transfer_captioner = build_captioner(language_prototxt, imagenet_no_transfer_weights, vocab)\n",
    "gen_captions_no_transfer_imagenet = imagenet_no_transfer_captioner.caption_images(feature_dict_imagenet, \n",
    "                                                                     feature_dict_imagenet.keys(), batch_size=1000)\n",
    "imagenet_transfer_captioner = build_captioner(language_prototxt, imagenet_transfer_weights, vocab)\n",
    "gen_captions_transfer_imagenet = imagenet_transfer_captioner.caption_images(feature_dict_imagenet, \n",
    "                                                      feature_dict_imagenet.keys(), batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, img in enumerate(coco_images):\n",
    "    img_read=mpimg.imread(img)\n",
    "    plt.figure()\n",
    "    plt.imshow(img_read)\n",
    "    plt.title(\"No transfer: %s\\nDCC Transfer: %s\" %(gen_captions_no_transfer[img], gen_captions_transfer[img]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, img in enumerate(imagenet_images):\n",
    "    img_read=mpimg.imread(img)\n",
    "    plt.figure()\n",
    "    plt.imshow(img_read)\n",
    "    plt.title(\"No transfer: %s\\nDCC Transfer: %s\" %(gen_captions_no_transfer_imagenet[img], \n",
    "                                                gen_captions_transfer_imagenet[img]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
